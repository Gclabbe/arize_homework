{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b1138b6-8ff0-4252-94bf-8cbfa5e96269",
   "metadata": {},
   "source": [
    "# Overall plan for integration of Langchain & Phoenix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c8e3a2-a1e9-4eb9-9bf5-a5069adc59eb",
   "metadata": {},
   "source": [
    "* Build RAG solution on a set of books using BloomZ (or Falcon maybe???)\n",
    "* Generate a series of Q&A\n",
    "* Leverage OpenAI + human feedback to build the truths\n",
    "* Integrate with Phoenix Eval using OpenAI as the judge\n",
    "* Create output report from Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f33b35-2520-4fb7-a4c6-c78b216b0957",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17274c8-60d7-4933-9ddb-fa5c9e652abd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2cb25a4-cc37-4541-85ed-2ad127c46653",
   "metadata": {},
   "source": [
    "# Ideas on how to make the process easier and more effective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b95e61-2cf4-4ed6-a0dd-14220922636c",
   "metadata": {},
   "source": [
    "* How can we integrate Eval into the langchain directly?\n",
    "* Conda environment.yml on startup / install ...\n",
    "    * not just our package, everything needed to get operating in a clean environment\n",
    "* Is there a better process to help the users generate the truth?\n",
    "* Can we automate the prototyping using LLMs?  \n",
    "    * i.e. point Phoenix at the data and we do the rest \n",
    "    * load, chain, construct challenges & truths, then test against several models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46eb172-0b4c-46f8-94bd-5ebcadcbff91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2503370a-3756-40a3-b981-beedce044bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c11befdc-1a5c-4158-9a2a-3bc60bcd3e8b",
   "metadata": {},
   "source": [
    "# Advancement concepts\n",
    "* Look into matching the output style of RoBerta for entailment\n",
    "    * supporting, irrelevant, not-supporting \n",
    "* Explore auto-tuning ... become the Optuna of LLMs projects\n",
    "    * Maybe integration of Optuna directly???\n",
    "    * Model parameters\n",
    "    * Key components like chunk size & overlap\n",
    "    * Randomization of chunks\n",
    "    * Prompt style suggestions\n",
    "* How to on <insert Cloud structure here>\n",
    "    * Google Cloud\n",
    "    * AWS Bedrock\n",
    "    * Azure <whatever>\n",
    "    * WhiteSpace\n",
    "    * Kaggle contest integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37f82f3-1025-4e03-8d13-ff2b2c30695d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508e8c5d-7db5-4f1f-a7c4-0af6c0b56ea4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66fc9834-35ff-437e-865c-8e06a73dc816",
   "metadata": {},
   "source": [
    "# Ideas on improvements to the metrics interface on Arize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4f7aea-2d10-4115-9a26-605c07635a18",
   "metadata": {},
   "source": [
    "## Simplify the interface\n",
    "* I get disoriented everytime I'm in there (maybe weekly)\n",
    "* Too many options for detail views + dropdowns to build out a view\n",
    "* Limits to amount of data being uploaded for prompts and responses needs to be fixed\n",
    "* Automated clustering and grouping\n",
    "    * When there are obvious outliers, don't make me play a video game to isolate them\n",
    "    * Easy clustering\n",
    "    * Then, just send sample from the different sets and let <foundation model> tell me what is different\n",
    "* Multi-lingual options -- easier than every today"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16a8b80-1ae3-463c-ac25-190ebcb026e4",
   "metadata": {},
   "source": [
    "## Autogen summaries using foundation model NLG\n",
    "\"customer X has shown a recent change in metric Y\"  \n",
    "\"the new model release has change accuracy by X%, however, precision seems to be down\"\n",
    "\n",
    "This can probably actually be done through NLG templating\n",
    "* Use the foundation model to generate templates that match the customer's language / features / model names, etc\n",
    "* Fill in the blanks of the template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c049b7-9811-4419-8ae3-a59d39c9da71",
   "metadata": {},
   "source": [
    "## Automated monitoring\n",
    "* Beyond dashboarding with so many things to click\n",
    "* Simplify the entire view to more modern HTML5 type interface\n",
    "* Block style model / customer / metrics with summary info and click-to-view details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368bf744-625b-42d0-a86f-22c7223b6024",
   "metadata": {},
   "source": [
    "## Integrated Phoenix Evaluation on RLHF\n",
    "* @ Compnay-X, we were sending RLHF opinions and comments\n",
    "    * Give value to RLHF component\n",
    "    * Downgrade negative sentiment if comment is more positive (reduce bias)\n",
    "    * On large population sets, search for bias (i.e. a particular customer \"always rejects the probability\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbfd8aa-021b-4130-9500-297531638067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1d182e-ec77-458d-a15a-f79821087fef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c3879c-ca47-4328-93b5-9281e4a35313",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
